{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    return x - y\n",
    "\n",
    "def training_set_generator(f,n):\n",
    "    '''\n",
    "    Generates a training set from a function with domain [-10, 10] x [-10, 10]\n",
    "    f - function to generate data\n",
    "    n - number of points to generate\n",
    "    '''\n",
    "    import random\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(n):\n",
    "        #x = (20*random.random() - 10,20*random.random() - 10)\n",
    "        x = np.array([[20*random.random() - 10],[20*random.random() - 10]])\n",
    "        inputs.append(x)\n",
    "        outputs.append(f(x[0,0], x[1,0]))\n",
    "    return(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "class Neural_Network():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = [\n",
    "            np.matrix(2*np.random.random((3,2)) - 1),\n",
    "            np.matrix(2*np.random.random((1,3)) - 1)\n",
    "        ]\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Takes in weighted sum of the inputs and normalizes\n",
    "        them through between 0 and 1 through a sigmoid function\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        The derivative of the sigmoid function used to\n",
    "        calculate necessary weight adjustments\n",
    "        \"\"\"\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "        \n",
    "    def think(self, inputs):\n",
    "        \"\"\"\n",
    "        Pass inputs through the neural network to get output\n",
    "        input: 2 x 1 array or matrix\n",
    "        output: 1 x 1 matrix\n",
    "        \"\"\"\n",
    "        #vectorize the sigmoid function so that it can be applied to matrices\n",
    "        sigmoid = np.vectorize(self.sigmoid)\n",
    "        \n",
    "        inputs = np.matrix(inputs.astype(float))\n",
    "        preactivation = []\n",
    "        outputs = []\n",
    "        preactivation.append(self.weights[0] * inputs)\n",
    "        outputs.append(sigmoid(preactivation[0]))\n",
    "        outputs.append(self.weights[1] * outputs[0])\n",
    "        return outputs, preactivation\n",
    "        \n",
    "    def train(self, training_inputs, training_outputs, num_epochs):\n",
    "        \"\"\"\n",
    "        We train the model through trial and error, adjusting the\n",
    "        synaptic weights each time to get a better result\n",
    "        \n",
    "        training_inputs = list of 2 x 1 arrays\n",
    "        training_outputs = list of numbers\n",
    "        num_epochs = number of times to run through the complete set of inputs\n",
    "        \"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "        \n",
    "            for x,y in zip(training_inputs, training_outputs):\n",
    "                # Pass training set through the neural network\n",
    "                outputs, preactivation = self.think(x)\n",
    "\n",
    "                # Calculate the error rate\n",
    "                error = y - outputs[1][0,0]\n",
    "\n",
    "                # Multiply error by input and gradient of the sigmoid function\n",
    "                # Less confident weights are adjusted more through the nature of the function\n",
    "                adjustments = [] \n",
    "            \n",
    "                adjustments.append(0.01 * 2 * error * np.transpose(outputs[0]))\n",
    "                matrix = np.matrix([[0,0],[0,0],[0,0]], dtype = float)\n",
    "                for i in range(3):\n",
    "                    for j in range(2):\n",
    "                        matrix[i,j] = x[j,0] * self.sigmoid_derivative(preactivation[0][i,0]) * self.weights[1][0,i] \n",
    "                adjustments.append(0.01 * 2 * error * matrix)\n",
    "                \n",
    "                #adjustments = np.dot(x.T, error * self.sigmoid_derivative(output))\n",
    "    \n",
    "                # Adjust synaptic weights\n",
    "                self.weights[1] += adjustments[0]\n",
    "                self.weights[0] += adjustments[1]\n",
    "            print(f'epoch {epoch + 1} complete')\n",
    "            print(f'MSE: {self.evaluate(training_inputs, training_outputs)}')\n",
    "    def evaluate(self, test_inputs, test_outputs):\n",
    "        '''\n",
    "        Calculate the mean squared error\n",
    "        test_inputs = list of 2 x 1 arrays\n",
    "        test_outputs = list of numbers\n",
    "        '''\n",
    "        error = 0\n",
    "        for x,y in zip(test_inputs, test_outputs):\n",
    "            error += (y - self.think(x)[0][1][0,0])**2\n",
    "        error /= len(test_inputs)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[-0.17482664, -0.82841739],\n",
       "         [ 0.9135875 ,  0.02715389],\n",
       "         [ 0.11852933,  0.34645425]]),\n",
       " matrix([[-0.06177072,  0.14992521, -0.89328363]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = Neural_Network()\n",
    "\n",
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 complete\n",
      "MSE: 11.419167270498603\n",
      "epoch 2 complete\n",
      "MSE: 11.36492736790554\n",
      "epoch 3 complete\n",
      "MSE: 11.483663339616914\n",
      "epoch 4 complete\n",
      "MSE: 11.144418275547528\n",
      "epoch 5 complete\n",
      "MSE: 10.795620809345431\n",
      "epoch 6 complete\n",
      "MSE: 12.672015751117195\n",
      "epoch 7 complete\n",
      "MSE: 10.826003964642778\n",
      "epoch 8 complete\n",
      "MSE: 11.019313038479519\n",
      "epoch 9 complete\n",
      "MSE: 11.72438434366318\n",
      "epoch 10 complete\n",
      "MSE: 11.129074279889101\n"
     ]
    }
   ],
   "source": [
    "training_inputs, training_outputs = training_set_generator(f, 10000)\n",
    "\n",
    "nn.train(training_inputs, training_outputs, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7543204515467413"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.think(np.array([[1],[10]]))[0][1][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
